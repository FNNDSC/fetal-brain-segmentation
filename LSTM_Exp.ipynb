{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datahandler import DataHandler\n",
    "from models.unet import *\n",
    "from generator import *\n",
    "from params import *\n",
    "from callbacks import getCallbacks\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import skimage.io as io\n",
    "\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set common variables\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "verbose = 1\n",
    "\n",
    "\n",
    "resetSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data and generators\n",
    "dh = DataHandler()\n",
    "tr_images, tr_masks, te_images, te_masks = dh.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = getUnet()\n",
    "unet_graph = tf.get_default_graph()\n",
    "\n",
    "with unet_graph.as_default():\n",
    "    unet_model.load_weights('logs/unet/kfold_unet/kfold_unet_dice_DA_K1/kfold_unet_dice_DA_K1_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generator(images, masks, batch_size):\n",
    "    i = 0\n",
    "    reset = False\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        c = batch_size * i \n",
    "        \n",
    "        if reset:\n",
    "            i = 0\n",
    "            c = 0\n",
    "            reset = False\n",
    "\n",
    "        for j in range(c, c + batch_size):\n",
    "            if j >= len(images):\n",
    "                reset = True\n",
    "                continue\n",
    "            \n",
    "            if j == 0:\n",
    "                res1 = np.expand_dims(np.zeros(images[j].shape), axis=0)\n",
    "            else:\n",
    "                img1 = np.expand_dims(images[j-1], axis=0)\n",
    "                with unet_graph.as_default():\n",
    "                    res1 = unet_model.predict(img1)\n",
    "\n",
    "            img2 = np.expand_dims(images[j], axis=0) \n",
    "            with unet_graph.as_default():\n",
    "                res2 = unet_model.predict(img2)\n",
    "\n",
    "            if j == images.shape[0]-1:\n",
    "                res3 = np.expand_dims(np.zeros(images[j].shape), axis=0)\n",
    "            else:\n",
    "                img3 = np.expand_dims(images[j+1], axis=0)\n",
    "                with unet_graph.as_default():\n",
    "                    res3 = unet_model.predict(img3)\n",
    "\n",
    "            res = np.concatenate((res1,res2,res3), axis=0)\n",
    "            res[res>=0.5] = 1\n",
    "            res[res<0.5] = 0\n",
    "            \n",
    "            mask = masks[j]\n",
    "            mask[mask == 255] = 1\n",
    "            \n",
    "            batch_features.append(res)\n",
    "            batch_labels.append(mask)\n",
    "        i += 1\n",
    "        \n",
    "        if len(batch_features) == 0:\n",
    "            res1 = np.expand_dims(np.zeros(images[0].shape), axis=0)\n",
    "            res2 = np.expand_dims(np.zeros(images[0].shape), axis=0)\n",
    "            res3 = np.expand_dims(np.zeros(images[0].shape), axis=0)\n",
    "            res = np.concatenate((res1,res2,res3), axis=0)\n",
    "            \n",
    "            mask = np.zeros(images[0].shape)\n",
    "            \n",
    "            batch_features.append(res)\n",
    "            batch_labels.append(mask)\n",
    "            \n",
    "\n",
    "        yield np.array(batch_features), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, MaxPooling2D, Dropout, Conv2D, Conv2DTranspose, TimeDistributed, Bidirectional, ConvLSTM2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from losses import *\n",
    "import math\n",
    "\n",
    "train_generator = generator(tr_images, tr_masks, 4)\n",
    "val_generator = generator(te_images, te_masks, 4)\n",
    "\n",
    "lstm_graph = tf.get_default_graph()\n",
    "\n",
    "with lstm_graph.as_default():\n",
    "\n",
    "    inputs = Input((3, 256, 256, 1))\n",
    "\n",
    "    bclstm = Bidirectional(ConvLSTM2D(32, 3, return_sequences = True, padding='same', activation = 'relu'))(inputs)\n",
    "    bclstm = Bidirectional(ConvLSTM2D(32, 3, return_sequences = True, padding='same', activation = 'relu'))(bclstm)\n",
    "\n",
    "    pool = TimeDistributed(MaxPooling2D(pool_size=2))(bclstm)\n",
    "\n",
    "    bclstm = Bidirectional(ConvLSTM2D(64, 3, return_sequences = True, padding='same', activation = 'relu'))(pool)\n",
    "    bclstm = Bidirectional(ConvLSTM2D(64, 3, return_sequences = True, padding='same', activation = 'relu'))(bclstm)\n",
    "    bclstm = Bidirectional(ConvLSTM2D(64, 3, padding='same', activation = 'relu'))(bclstm)\n",
    "\n",
    "    up = Conv2DTranspose(64,3, strides=2, padding='same', activation = 'relu')(bclstm)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding='same')(up)\n",
    "\n",
    "    outputs = Conv2D(1, (1,1), activation = 'sigmoid')(conv)\n",
    "\n",
    "    model = Model(input = inputs, output = outputs)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 1e-4),\n",
    "            loss = binary_crossentropy, metrics = [dice_coef])\n",
    "    \n",
    "    model.fit_generator(train_generator, validation_data=val_generator, \n",
    "                        validation_steps=math.floor(len(te_images)/4),\n",
    "                        callbacks = [ModelCheckpoint('logs/LSTM/', monitor='val_loss', verbose=1, save_best_only=True)],\n",
    "                        steps_per_epoch=math.floor(len(te_images)/4), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1925\n",
    "with unet_graph.as_default():\n",
    "    img1 = np.expand_dims(tr_images[j-1], axis=0)\n",
    "    res1 = unet_model.predict(img1)\n",
    "    res1[res1>=0.5] = 1\n",
    "    res1[res1<0.5] = 0\n",
    "    \n",
    "    img2 = np.expand_dims(tr_images[j], axis=0) \n",
    "    res2 = unet_model.predict(img2)\n",
    "    res2[res2>=0.5] = 1\n",
    "    res2[res2<0.5] = 0\n",
    "    \n",
    "    img3 = np.expand_dims(tr_images[j+1], axis=0)\n",
    "    res3 = unet_model.predict(img3)\n",
    "    res3[res3>=0.5] = 1\n",
    "    res3[res3<0.5] = 0\n",
    "    \n",
    "plt.gray()\n",
    "\n",
    "res = np.array([np.concatenate((res1,res2,res3), axis=0)])\n",
    "res[res >= 0.5] = 1\n",
    "res[res < 0.5] = 0\n",
    "\n",
    "print(res.shape)\n",
    "\n",
    "with lstm_graph.as_default():\n",
    "    r = model.predict(res)\n",
    "    r[r<0.5] = 0\n",
    "    r[r>0.5] = 1\n",
    "    print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(np.squeeze(tr_images[j] + res2[0] * 255 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(tr_images[j] + r[0] * 255 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(tr_images[j] + tr_masks[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "mask = tr_masks[j]\n",
    "mask[mask==255] = 1\n",
    "\n",
    "res2[res2>=0.5] = 1\n",
    "res2[res2<0.5] = 0\n",
    "\n",
    "print(f1_score(r[0].flatten(), mask.flatten()))\n",
    "print(f1_score(res2[0].flatten(), mask.flatten()))      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
