{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13992623288389615112\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10204282880\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13626943510793637129\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from medpy.io import save\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, jaccard_similarity_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fbs import FBSDataset, FBSConfig\n",
    "  \n",
    "from mrcnn import model as modellib    \n",
    "from mrcnn.utils import extract_bboxes, non_max_suppression\n",
    "\n",
    "from datahandler import DataHandler\n",
    "  \n",
    "ROOT_DIR = os.path.abspath('../../')\n",
    "sys.path.append(ROOT_DIR)         \n",
    "      \n",
    "LOG_DIR = os.path.join(ROOT_DIR, 'logs')\n",
    "MODEL_DIR = os.path.join(LOG_DIR, \"mask_rcnn\")\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, 'data/')\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, 'test/images/*')\n",
    "MASKS_DIR = os.path.join(DATASET_DIR, 'test/masks/*')\n",
    "\n",
    "dh = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 17\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(FBSConfig):\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    DETECTION_NMS_THRESHOLD = 0.7\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(        \n",
    "         mode='inference',\n",
    "         config=inference_config,\n",
    "         model_dir=MODEL_DIR\n",
    "         )      \n",
    "  \n",
    "model_path = '../../logs/mask_rcnn/fbs_resnet50_da_lr_maskexp_5620190305T1227/mask_rcnn_fbs_resnet50_da_lr_maskexp_56_0017.h5'\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destiny_directory(data_origin, dice_score):\n",
    "    pre = './data/eval/mask_rcnn_'+data_origin+'/'\n",
    "    if dice_score >= 98:\n",
    "        return pre + 'dice_98_100/'\n",
    "    elif dice_score >= 96:\n",
    "        return pre + 'dice_96_98/'\n",
    "    elif dice_score >= 94:\n",
    "        return pre + 'dice_94_96/'\n",
    "    elif dice_score >= 92:\n",
    "        return pre + 'dice_92_94/'\n",
    "    elif dice_score >= 90:\n",
    "        return pre + 'dice_90_92/'\n",
    "    elif dice_score >= 88:\n",
    "        return pre + 'dice_88_90/'\n",
    "    elif dice_score >= 85:\n",
    "        return pre + 'dice_85_88'\n",
    "    elif dice_score >= 80:\n",
    "        return pre + 'dice_80_85/'\n",
    "    elif dice_score >= 70:\n",
    "        return pre + 'dice_70_80/'\n",
    "    elif dice_score >= 60:\n",
    "        return pre + 'dice_60_70/'\n",
    "    else:\n",
    "        return pre + 'dice_less_60'\n",
    "    \n",
    "def getFileName(fname):\n",
    "    original_name = fname.split('/')[-1]\n",
    "    original_name = original_name[:original_name.index('.')]\n",
    "    return original_name\n",
    "\n",
    "def evaluateMask(ground_truth, prediction):\n",
    "    #convert to boolean values and flatten\n",
    "    ground_truth = np.asarray(ground_truth, dtype=np.bool).flatten()\n",
    "    prediction = np.asarray(prediction, dtype=np.bool).flatten()    \n",
    "    return f1_score(ground_truth, prediction)\n",
    "\n",
    "def saveAll(data_origin, fname, hdr, image, gt_mask, pred_mask, score):\n",
    "    fname = getFileName(fname)\n",
    "    dice_score = int(score * 100)\n",
    "    \n",
    "    save_path = destiny_directory(data_origin, dice_score)\n",
    "    save_path = os.path.join(ROOT_DIR, save_path)\n",
    "        \n",
    "    save(pred_mask, os.path.join(save_path, fname + '_pred_' \n",
    "        + str(dice_score) + '.nii'), hdr)\n",
    "    save(image, os.path.join(save_path, fname + '_img.nii'), hdr)\n",
    "    save(gt_mask, os.path.join(save_path, fname + '_mask.nii'), hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_prediction(model, config, image):\n",
    "\n",
    "    \"\"\"Test time augmentation method using non-maximum supression\"\"\"\n",
    "\n",
    "    masks = []\n",
    "    scores = []\n",
    "    boxes = []\n",
    "    \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    result = model.detect([image], verbose=0)[0]\n",
    "    \n",
    "    if result['masks'].shape[2] == 0:\n",
    "        return result\n",
    "    \n",
    "    masks.append(result['masks'])\n",
    "    scores.append(result['scores'])\n",
    "    boxes.append(extract_bboxes(result['masks']))\n",
    "\n",
    "    temp_img = np.fliplr(image)\n",
    "    result = model.detect([temp_img], verbose=0)[0]\n",
    "    mask = np.fliplr(result['masks'])\n",
    "    masks.append(mask)\n",
    "    scores.append(result['scores'])\n",
    "    boxes.append(extract_bboxes(mask))\n",
    "\n",
    "    temp_img = np.flipud(image)\n",
    "    result = model.detect([temp_img], verbose=0)[0]\n",
    "    mask = np.flipud(result['masks'])\n",
    "    masks.append(mask)\n",
    "    scores.append(result['scores'])\n",
    "    boxes.append(extract_bboxes(mask))\n",
    "    \n",
    "    temp_img = np.roll(image, 10, axis=0)\n",
    "    result = model.detect([temp_img], verbose=0)[0]\n",
    "    mask = np.roll(result['masks'], -10, axis=0)\n",
    "    masks.append(mask)\n",
    "    scores.append(result['scores'])\n",
    "    boxes.append(extract_bboxes(mask))\n",
    "    \n",
    "    temp_img = np.roll(image, 10, axis=1)\n",
    "    result = model.detect([temp_img], verbose=0)[0]\n",
    "    mask = np.roll(result['masks'], -10, axis=1)\n",
    "    masks.append(mask)\n",
    "    scores.append(result['scores'])\n",
    "    boxes.append(extract_bboxes(mask))\n",
    "\n",
    "    angles = [90,180,270]\n",
    "    for angle in angles:\n",
    "        temp_img = np.rot90(image, k=angle, axes=(0, 1))\n",
    "        result = model.detect([temp_img], verbose=0)[0]\n",
    "        mask = np.rot90(result['masks'], k=-angle, axes=(0, 1))\n",
    "        masks.append(mask)\n",
    "        scores.append(result['scores'])\n",
    "        boxes.append(extract_bboxes(mask))\n",
    "\n",
    "    masks = np.concatenate(masks, axis=-1)\n",
    "    scores = np.concatenate(scores, axis=-1)\n",
    "    boxes = np.concatenate(boxes, axis=0)\n",
    "\n",
    "    # config.DETECTION_NMS_THRESHOLD)\n",
    "    keep_ind = non_max_suppression(boxes, scores, 0.5)[0]\n",
    "    masks = masks[:, :, keep_ind]\n",
    "    scores = scores[keep_ind]\n",
    "\n",
    "    results['masks'] = masks\n",
    "    results['scores'] = scores\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAll(data_origin, dict_prefix, tta=False):\n",
    "    data_origin+=dict_prefix\n",
    "    \n",
    "    image_paths = glob.glob(IMAGES_DIR)\n",
    "    masks_paths = glob.glob(MASKS_DIR)\n",
    "    dice_scores = []\n",
    "\n",
    "    for image_path, mask_path in tqdm(zip(image_paths, masks_paths),\n",
    "                                      total=len(image_paths)):\n",
    "        #get header of image to later save mask\n",
    "        full_image, hdr = dh.getImageData(image_path)\n",
    "        gt_mask, _ = dh.getImageData(mask_path, is_mask=True)\n",
    "\n",
    "        dataset_val = FBSDataset()        \n",
    "        dataset_val.load_data(DATASET_DIR, \n",
    "                              subset='eval', \n",
    "                              image_file=image_path, \n",
    "                              mask_file=mask_path)\n",
    "        dataset_val.prepare() \n",
    "    \n",
    "        prediction = []\n",
    "        \n",
    "        for img_id in dataset_val.image_ids:\n",
    "            image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "            dataset_val, inference_config, img_id, use_mini_mask=False)\n",
    "            \n",
    "            #if tta:\n",
    "            #    results = ensemble_prediction(model, inference_config, image)\n",
    "            #    r = results\n",
    "                \n",
    "            #else:\n",
    "            #change if it breaks\n",
    "            results = model.detect([image], verbose = 0, tta=tta)\n",
    "            r = results[0]\n",
    "                \n",
    "            pred = r['masks']\n",
    "\n",
    "            if(len(pred.shape) > 2 and pred.shape[2] == 0):\n",
    "                if tta:\n",
    "                    pred = np.zeros((256,256))\n",
    "                else:\n",
    "                    pred = np.zeros((256,256,1))\n",
    "            \n",
    "            prediction.append(pred)\n",
    "\n",
    "        pred_mask = np.asarray(prediction, dtype=np.bool)\n",
    "\n",
    "        score = evaluateMask(gt_mask, pred_mask)\n",
    "        dice_scores.append(score)\n",
    "        \n",
    "        saveAll(data_origin, image_path, hdr, full_image, \n",
    "                gt_mask, pred_mask, score)\n",
    "        \n",
    "    \n",
    "    print('Number of images %d'%len(dice_scores))\n",
    "    print(np.mean(dice_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [05:23<00:00,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images 43\n",
      "0.8907982777923956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = ''\n",
    "predictAll(data_origin, dict_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 21/43 [10:42<12:56, 35.30s/it]"
     ]
    }
   ],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = 'TTA'\n",
    "predictAll(data_origin, dict_prefix, tta=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
