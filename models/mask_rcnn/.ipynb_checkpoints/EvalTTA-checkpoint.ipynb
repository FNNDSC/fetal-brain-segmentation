{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12024568863552552414\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10112886375\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16712919891816202248\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from medpy.io import save\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, jaccard_similarity_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fbs import FBSDataset, FBSConfig\n",
    "  \n",
    "from mrcnn import model as modellib    \n",
    "from mrcnn.utils import extract_bboxes, non_max_suppression\n",
    "\n",
    "from datahandler import DataHandler\n",
    "  \n",
    "ROOT_DIR = os.path.abspath('../../')\n",
    "sys.path.append(ROOT_DIR)         \n",
    "      \n",
    "LOG_DIR = os.path.join(ROOT_DIR, 'logs')\n",
    "MODEL_DIR = os.path.join(LOG_DIR, \"mask_rcnn\")\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, 'data/')\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, 'test/images/*')\n",
    "MASKS_DIR = os.path.join(DATASET_DIR, 'test/masks/*')\n",
    "\n",
    "dh = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 70\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(FBSConfig):\n",
    "    IMAGES_PER_GPU = 1\n",
    "    MASK_SHAPE = [56,56]\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(        \n",
    "         mode='inference',\n",
    "         config=inference_config,\n",
    "         model_dir=MODEL_DIR\n",
    "         )      \n",
    "  \n",
    "model_path = '../../logs/mask_rcnn/fbs_resnet50_da_tf_nominimask_1channel20190319T1724/mask_rcnn_fbs_resnet50_da_tf_nominimask_1channel_0070.h5'\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destiny_directory(data_origin, dice_score):\n",
    "    pre = './data/eval/mask_rcnn_'+data_origin+'/'\n",
    "    if dice_score >= 98:\n",
    "        return pre + 'dice_98_100/'\n",
    "    elif dice_score >= 96:\n",
    "        return pre + 'dice_96_98/'\n",
    "    elif dice_score >= 94:\n",
    "        return pre + 'dice_94_96/'\n",
    "    elif dice_score >= 92:\n",
    "        return pre + 'dice_92_94/'\n",
    "    elif dice_score >= 90:\n",
    "        return pre + 'dice_90_92/'\n",
    "    elif dice_score >= 88:\n",
    "        return pre + 'dice_88_90/'\n",
    "    elif dice_score >= 85:\n",
    "        return pre + 'dice_85_88'\n",
    "    elif dice_score >= 80:\n",
    "        return pre + 'dice_80_85/'\n",
    "    elif dice_score >= 70:\n",
    "        return pre + 'dice_70_80/'\n",
    "    elif dice_score >= 60:\n",
    "        return pre + 'dice_60_70/'\n",
    "    else:\n",
    "        return pre + 'dice_less_60'\n",
    "    \n",
    "def getFileName(fname):\n",
    "    original_name = fname.split('/')[-1]\n",
    "    original_name = original_name[:original_name.index('.')]\n",
    "    return original_name\n",
    "\n",
    "def evaluateMask(ground_truth, prediction):\n",
    "    #convert to boolean values and flatten\n",
    "    ground_truth = np.asarray(ground_truth, dtype=np.bool).flatten()\n",
    "    prediction = np.asarray(prediction, dtype=np.bool).flatten()    \n",
    "    return f1_score(ground_truth, prediction)\n",
    "\n",
    "def saveAll(data_origin, fname, hdr, image, gt_mask, pred_mask, score):\n",
    "    fname = getFileName(fname)\n",
    "    dice_score = int(score * 100)\n",
    "    \n",
    "    save_path = destiny_directory(data_origin, dice_score)\n",
    "    save_path = os.path.join(ROOT_DIR, save_path)\n",
    "        \n",
    "    save(pred_mask, os.path.join(save_path, fname + '_pred_' \n",
    "        + str(dice_score) + '.nii'), hdr)\n",
    "    save(image, os.path.join(save_path, fname + '_img.nii'), hdr)\n",
    "    save(gt_mask, os.path.join(save_path, fname + '_mask.nii'), hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def vflip(image):\n",
    "    return np.flipud(image)\n",
    "\n",
    "def hflip(image):\n",
    "    return np.fliplr(image)\n",
    "\n",
    "def rotate(image, k):\n",
    "    return np.rot90(image, k, axes=(0,1))\n",
    "\n",
    "def ensemble_prediction(model, image):\n",
    "    \"\"\"Test time augmentation method using non-maximum supression\"\"\"\n",
    "    masks = []\n",
    "    results = {}\n",
    "    \n",
    "    result = model.detect([image], verbose=0)[0]\n",
    "    \n",
    "    if result['masks'].shape[2] == 0:\n",
    "        return result\n",
    "    \n",
    "    masks.append(result['masks'])\n",
    "    \n",
    "    flip_v = [True, False]\n",
    "    flip_h = [True, False]\n",
    "    rotations = [0,1,2,3]\n",
    "\n",
    "    transformations = list(itertools.product(flip_v, flip_h, rotations))\n",
    "\n",
    "    for fv, fh, r in transformations:\n",
    "        result = image\n",
    "        result = vflip(result) if fv else result\n",
    "        result = hflip(result) if fh else result\n",
    "        result = rotate(result, r)\n",
    "        result = model.detect([result], verbose=0)[0]['masks']\n",
    "        result = rotate(result, -r)\n",
    "        result = hflip(result) if fh else result\n",
    "        result = vflip(result) if fv else result\n",
    "        masks.append(result)\n",
    "        \n",
    "    masks = np.concatenate(masks, axis=-1)\n",
    "    masks = np.sum(masks, axis=-1, keepdims=True)\n",
    "    \n",
    "    cut_off = len(transformations) // 2\n",
    "    masks[masks <= cut_off] == 0\n",
    "    masks[masks > cut_off] == 1\n",
    "    results['masks'] = masks\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAll(data_origin, dict_prefix, tta=False, dilate=False, d_size=None):\n",
    "    data_origin+=dict_prefix\n",
    "    \n",
    "    image_paths = glob.glob(IMAGES_DIR)\n",
    "    masks_paths = glob.glob(MASKS_DIR)\n",
    "    dice_scores = []\n",
    "    \n",
    "    if dilate:\n",
    "        kernel = np.ones(d_size,np.uint8)\n",
    "\n",
    "    for image_path, mask_path in tqdm(zip(image_paths, masks_paths),\n",
    "                                      total=len(image_paths)):\n",
    "        #get header of image to later save mask\n",
    "        full_image, hdr = dh.getImageData(image_path)\n",
    "        gt_mask, _ = dh.getImageData(mask_path, is_mask=True)\n",
    "\n",
    "        dataset_val = FBSDataset()        \n",
    "        dataset_val.load_data(DATASET_DIR, \n",
    "                              subset='eval', \n",
    "                              image_file=image_path, \n",
    "                              mask_file=mask_path)\n",
    "        dataset_val.prepare() \n",
    "    \n",
    "        prediction = []\n",
    "        \n",
    "        for img_id in dataset_val.image_ids:\n",
    "            image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "            dataset_val, inference_config, img_id, use_mini_mask=False)\n",
    "\n",
    "            if tta:\n",
    "                results = ensemble_prediction(model, image)\n",
    "                r = results\n",
    "                \n",
    "            else:\n",
    "                results = model.detect([image], verbose = 0)\n",
    "                r = results[0]\n",
    "                \n",
    "            pred = r['masks']\n",
    "\n",
    "            if(len(pred.shape) > 2 and pred.shape[2] == 0):\n",
    "                pred = np.zeros((256,256,1))\n",
    "            \n",
    "            if dilate:\n",
    "                pred = np.asarray(pred, dtype=np.uint8)\n",
    "                pred = cv2.dilate(pred,kernel,iterations = 1)\n",
    "\n",
    "            prediction.append(pred)\n",
    "\n",
    "        pred_mask = np.asarray(prediction, dtype=np.bool)\n",
    "\n",
    "        score = evaluateMask(gt_mask, pred_mask)\n",
    "        dice_scores.append(score)\n",
    "        \n",
    "        saveAll(data_origin, image_path, hdr, full_image, \n",
    "                gt_mask, pred_mask, score)\n",
    "        \n",
    "    \n",
    "    print('Number of images %d'%len(dice_scores))\n",
    "    print(np.mean(dice_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [04:48<00:00,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images 43\n",
      "0.9056250096248001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = ''\n",
    "predictAll(data_origin, dict_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 13/43 [11:44<27:16, 54.56s/it]"
     ]
    }
   ],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = 'TTA'\n",
    "predictAll(data_origin, dict_prefix, tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = 'Dilate3'\n",
    "predictAll(data_origin, dict_prefix, dilate=True, d_size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = 'test'\n",
    "dict_prefix = 'Dilate5'\n",
    "predictAll(data_origin, dict_prefix, dilate=True, d_size=(5,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
